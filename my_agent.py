import openai
from base_url_api_provider import BASE_URL, API_KEY

BASE_URL: str
API_KEY: str


class MyAgent:
    def __init__(self, 
            model_name: str, use_thinking_params: bool = False, 
            retry_when_timeout: bool = False, timeout_seconds = 10, 
            include_reasoning_in_history = None,
            temperature = openai.NOT_GIVEN, top_p = openai.NOT_GIVEN,
            random_seed = openai.NOT_GIVEN):
        """
        Initialize the agent using the global BASE_URL and API_KEY.
        
        Args:
            model_name (str): The name of the model to use for completions.
            use_thinking_params (bool): Whether to apply special reasoning/thinking parameters for specific models.
        Models = [
            "deepseek-r1-250120",
            "deepseek-v3-250324",
            "doubao-1-5-pro-256k-250115",
            "doubao-1-5-thinking-pro-250415",
            "gemini-2.5-flash-preview-04-17",
            "gpt-4.1-2025-04-14",
            "gpt-4.1-mini-2025-04-14",
            "o4-mini",
            "claude-3-7-sonnet-20250219",
        ]
        """
        self.model_name = model_name
        self.use_thinking_params = use_thinking_params
        self.history = []  # Maintain internal chat history
        self.detailed_history_response = [] # Maintain other metadata of each response rather than just replies
        
        self.retry_when_timeout = retry_when_timeout
        
        if include_reasoning_in_history is not None:
            self.include_reasoning_in_history = include_reasoning_in_history
        else:
            if (use_thinking_params or 
                self.model_name in ["deepseek-r1-250120", "doubao-1-5-thinking-pro-250415"]):
                self.include_reasoning_in_history = True
            else:
                self.include_reasoning_in_history = False

        self.seed = random_seed
        self.temperature = temperature
        self.top_p = top_p

        # Assuming BASE_URL and API_KEY are defined globally
        global BASE_URL, API_KEY
        
        self.client = openai.OpenAI(
            api_key=API_KEY,
            base_url=BASE_URL,
            timeout=timeout_seconds,  # Default timeout
            max_retries=0
        )

    def continue_conversation(self, additional_observation: dict) -> str:
        """
        Process additional observations from other agents and respond.
        
        Args:
            additional_observation (dict): Observations from other agents in the format {"agent_name": "message"}.

        Returns:
            str: The response generated by this agent based on the inputs.
        """
        # Add each observation to the history with its corresponding role
        for role, content in additional_observation.items():
            if (role == "system"):
                self.history.append({"role": "system", "content": content})
            else:
                self.history.append({"role": "user", "content": f"({role}:) {content}"})

        create_kwargs = {
            "model": self.model_name,
            "messages": self.history,
            "stream": False,
            "seed": self.seed,
            "temperature": self.temperature,
            "top_p": self.top_p
        }

        # Apply thinking/reasoning parameters if needed
        if self.use_thinking_params:
            if self.model_name == "gemini-2.5-flash-preview-04-17":
                create_kwargs["reasoning_effort"] = "low"
            elif self.model_name == "claude-3-7-sonnet-20250219":
                create_kwargs["extra_body"] = {"thinking": {"type": "enabled", "budget_tokens": 20}}
            else:
                print("标记为思考模式但无特定参数配置")

        # Get response from LLM
        while True:
            try:
                response = self.client.chat.completions.create(**create_kwargs)
                reply = response.choices[0].message.content.strip()
                if self.include_reasoning_in_history:
                    reasoning_content = response.choices[0].message.reasoning_content
                    reply = "reasoning_content: " + reasoning_content + "reply: " + reply
            except Exception as e:
                reply = f"Error generating response: {e}"
                print(reply)
            finally:
                if self.retry_when_timeout:
                    continue
                else: 
                    break
        # Add agent's own reply to history
        self.history.append({"role": "assistant", "content": reply})
        self.detailed_history_response.append({"response": response, "reply_block": self.history[-1]})
        return reply
    
    def close(self):
        self.client.close()